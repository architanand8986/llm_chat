# LLM Chat App (Groq API + React)

A lightweight, responsive chat interface powered by the [Groq API](https://groq.com/) for blazing-fast large language model responses.
Built with **React** and **Tailwind CSS**, this app supports multiple Groq models, persistent chat history, and a clean UI.
<br>
To check out the deployed app <a href = "https://llm-chat-mu.vercel.app/">Click here</a>

---

## ðŸš€ Features

- **Multiple LLM Models** â€“ Choose from Groq's available models.
- **Streaming Responses** â€“ Messages appear in real-time.
- **Persistent Chat** â€“ Chat history stored in `localStorage`.
- **Clear Chat** â€“ Reset conversation with one click.
- **Responsive Design** â€“ Works on all screen sizes.

---

## ðŸ“¦ Tech Stack

- **React** (Functional Components + Hooks)
- **Tailwind CSS**
- **Groq SDK** (`groq-sdk`)
- **Vite**

---

## ðŸ›  Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/architanand8986/llm_chat.git
   cd llm_chat
   ```

2. **Install dependencies**

   ```bash
   npm install
   ```

   or

   ```bash
   yarn install
   ```

3. **Add your Groq API Key**
   Create a `.env` file in the root directory:

   ```env
   NEXT_PUBLIC_GROQ_API_KEY=your_api_key_here
   ```

4. **Run the app**

   ```bash
   npm run dev
   ```

   or

   ```bash
   yarn dev
   ```

---

## ðŸ“‚ Project Structure

```
llm_chat/
â”œâ”€â”€ backend/                     # Backend logic (if any)
â”œâ”€â”€ public/                      # Public assets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assets/                  # Images and other static files
â”‚   â”œâ”€â”€ components/              # UI components
â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â””â”€â”€ ModelSelection.jsx
â”‚   â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useCache.js
â”‚   â”‚   â”œâ”€â”€ useChat.js
â”‚   â”‚   â””â”€â”€ useGroq.js
â”‚   â”œâ”€â”€ utils/                   # Helper functions / constants
â”‚   â”‚   â””â”€â”€ constants.js
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ index.css
â”‚   â””â”€â”€ main.jsx
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ eslint.config.js
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ README.md
â””â”€â”€ vite.config.js
```

---

## ðŸ§  Usage

1. Select a model from the dropdown.
2. Type your question in the input field.
3. Press **Enter** or click **Send**.
4. Use **Clear Chat** to reset the conversation.

---

## ðŸ”§ Configuration

To update available models, edit:

```
src/utils/constants.js
```

Example:

```javascript
export const GROQ_MODELS = ["llama-3.3-70b-versatile", "llama-2-70b-chat"];
```

---

## ðŸ“œ License

This project is licensed under the **MIT License**.

---

## ðŸ™Œ Acknowledgements

- [Groq](https://groq.com/) for their API.
- [Tailwind CSS](https://tailwindcss.com/) for styling.
